{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-agent simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from gym import spaces\n",
    "import copy\n",
    "\n",
    "from stable_baselines.common.policies import *\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.version.VERSION[0] == '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_area():\n",
    "    B = -10\n",
    "    BORDER = [B, B, B, B, B, B]\n",
    "    init_area = np.array([BORDER])\n",
    "    \n",
    "    for i in range(4):\n",
    "        row = np.random.random_sample(4) * 6\n",
    "        row = row.astype(int)\n",
    "        row = np.insert(row, 0, B)\n",
    "        row = np.append(row, B)\n",
    "        init_area = np.concatenate((init_area, [row]))\n",
    "    \n",
    "    init_area = np.concatenate((init_area, [BORDER]))\n",
    "    \n",
    "    return init_area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_maps = []\n",
    "\n",
    "class Agent(gym.Env):\n",
    "    \n",
    "    def __init__(self, area):\n",
    "        self.area = area\n",
    "        self.reward_rangee = (0, 10)\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "        self.observation_space = spaces.MultiDiscrete(nvec=[30, 30, 30, 30, 30, 30, 30, 30, 30])\n",
    "        \n",
    "    def reset(self):\n",
    "        self.fitness = 10\n",
    "        self.position = (1, 1)\n",
    "        self.reward_sum = 0\n",
    "        self.area = copy.deepcopy(generate_area())\n",
    "        \n",
    "        return self._next_observation()\n",
    "    \n",
    "    def _next_observation(self):\n",
    "        x, y = self.position\n",
    "        visible = self.area[x-1:x+2, x-1:x+2]\n",
    "        \n",
    "        return visible.reshape(9)\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        reward = 0\n",
    "        x, y = self.position\n",
    "        \n",
    "        if action < 4:\n",
    "            if action == 0:\n",
    "                new_y = y-1 if y>1 else y\n",
    "                self.position = x, new_y\n",
    "            if action == 1: \n",
    "                new_y = y+1 if y<4 else y\n",
    "                self.position = x, new_y\n",
    "            if action == 2:\n",
    "                new_x = x+1 if x<4 else x\n",
    "                self.position = new_x, y\n",
    "            if action == 3:\n",
    "                new_x = x-1 if x>1 else x\n",
    "                self.position = new_x, y\n",
    "            x, y = self.position\n",
    "            self.fitness -= 1\n",
    "        else:\n",
    "            self.reward_sum += self.area[x, y]\n",
    "            self.fitness += self.area[x, y]\n",
    "            reward = self.area[x, y]\n",
    "            self.area[x, y] = 0\n",
    "        \n",
    "        done = self.fitness <= 0\n",
    "        \n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        copied_map = copy.deepcopy(self.area)\n",
    "        x, y = self.position\n",
    "        copied_map[x,y] = -12\n",
    "        stored_maps.append(copied_map)       \n",
    "        print(self.reward_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([lambda: Agent(generate_area())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = A2C(MlpPolicy, env, verbose=0)\n",
    "model.learn(total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "11\n",
      "11\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "17\n",
      "17\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "22\n",
      "22\n",
      "22\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "28\n",
      "28\n",
      "28\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "33\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "0\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "17\n",
      "17\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for i in range(200):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "for i in range(200):\n",
    "    plt.pcolor(stored_maps[i])\n",
    "    camera.snap()\n",
    "animation = camera.animate()\n",
    "animation.save('simulation4.gif', writer = 'imagemagick')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
